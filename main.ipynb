{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews\n",
    "\n",
    "This project will create a machine learning model that is able to predict if a given movie review is positive or negative.\n",
    "It uses Stanford's Large Movie Review Dataset: [Link](https://ai.stanford.edu/~amaas/data/sentiment/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "These libraries are included in the `requirements.txt` file and can be downloaded using a simple:\n",
    "`pip install -r requirements.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1730794127743,
     "user": {
      "displayName": "Mahad",
      "userId": "09697981992789353247"
     },
     "user_tz": -240
    },
    "id": "YY5fCiH0ZI2F"
   },
   "outputs": [],
   "source": [
    "# Expanding contractions\n",
    "import contractions\n",
    "\n",
    "# Working with datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Text cleaning\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# ML related\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1730794128315,
     "user": {
      "displayName": "Mahad",
      "userId": "09697981992789353247"
     },
     "user_tz": -240
    },
    "id": "l4pb2MO_cjKX",
    "outputId": "490d39e3-4d6d-41dc-debb-ebd559115a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review sentiment\n",
      "0    One of the other reviewers has mentioned that ...  positive\n",
      "1    A wonderful little production. <br /><br />The...  positive\n",
      "2    I thought this was a wonderful way to spend ti...  positive\n",
      "3    Basically there's a family where a little boy ...  negative\n",
      "4    Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "..                                                 ...       ...\n",
      "995  Nothing is sacred. Just ask Ernie Fosselius. T...  positive\n",
      "996  I hated it. I hate self-aware pretentious inan...  negative\n",
      "997  I usually try to be professional and construct...  negative\n",
      "998  If you like me is going to see this in a film ...  negative\n",
      "999  This is like a zoology textbook, given that it...  negative\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Path to where the dataset is located\n",
    "DATASET_PATH = \"./dataset/IMDB Dataset.csv\"\n",
    "\n",
    "# Read the local dataset containing movie reviews and their sentiments\n",
    "df = pd.read_csv(DATASET_PATH)[:1000]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "p = re.compile(\"<.*?>\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_html(text):\n",
    "    cleantext = re.sub(p, \"\", text)\n",
    "    return cleantext\n",
    "\n",
    "def expand_contractions(text):\n",
    "    expanded = [contractions.fix(word) for word in text.split()]\n",
    "    return \" \".join(expanded)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text.split() if word not in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "def clean(text):\n",
    "    text = remove_html(text)\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_stopwords(text.lower())\n",
    "    return lemmatize(text)\n",
    "\n",
    "df[\"review\"] = df[\"review\"].apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                review sentiment\n",
      "0    one reviewer mentioned watching 1 oz episode h...  positive\n",
      "1    wonderful little production. filming technique...  positive\n",
      "2    thought wonderful way spend time hot summer we...  positive\n",
      "3    basically family little boy (jake) think zombi...  negative\n",
      "4    petter mattei's \"love time money\" visually stu...  positive\n",
      "..                                                 ...       ...\n",
      "695  okay stupid,they say making another nightmare ...  negative\n",
      "696  everyone, name may sound weird, nothing else! ...  positive\n",
      "697  finally released good modesty blaise movie, te...  positive\n",
      "698  now, game's stale, right?the joke done. over. ...  positive\n",
      "699  decided watch movie would seen carol lombard m...  negative\n",
      "\n",
      "[700 rows x 2 columns]\n",
      "                                                review sentiment\n",
      "700  unfortunately spoiler review nothing spoil mov...  negative\n",
      "701  enjoyed watching well acted movie much!it well...  positive\n",
      "702  hypothetical situation abound, one-time direct...  negative\n",
      "703  must admit, expecting something quite differen...  positive\n",
      "704  happy live american small town. whenever shown...  positive\n",
      "..                                                 ...       ...\n",
      "995  nothing sacred. ask ernie fosselius. days, eve...  positive\n",
      "996  hated it. hate self-aware pretentious inanity ...  negative\n",
      "997  usually try professional constructive criticiz...  negative\n",
      "998  like going see film history class something li...  negative\n",
      "999  like zoology textbook, given depiction animal ...  negative\n",
      "\n",
      "[300 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a training and testing set\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Verify data\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup vectorizer to convert words into word vectors\n",
    "vectorizer = TfidfVectorizer(\n",
    "    min_df=5, max_df=0.8, sublinear_tf=True\n",
    ")\n",
    "train_vectors = vectorizer.fit_transform(train_data[\"review\"])\n",
    "test_vectors = vectorizer.transform(test_data[\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using a Support Vector Machine\n",
    "clf = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "clf.fit(train_vectors, train_data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:  {'precision': 0.8835616438356164, 'recall': 0.7914110429447853, 'f1-score': 0.8349514563106796, 'support': 163.0}\n",
      "negative:  {'precision': 0.7792207792207793, 'recall': 0.8759124087591241, 'f1-score': 0.8247422680412371, 'support': 137.0}\n",
      "accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Predict the sentiments of the test data and compare to the actual sentiments\n",
    "predictions = clf.predict(test_vectors)\n",
    "report = classification_report(test_data[\"sentiment\"], predictions, output_dict=True)\n",
    "\n",
    "print(\"positive: \", report[\"positive\"])\n",
    "print(\"negative: \", report[\"negative\"])\n",
    "print(\"accuracy:\", report[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive'] [[0.11412153 0.88587847]]\n"
     ]
    }
   ],
   "source": [
    "# Test with custom reviews\n",
    "# Change this to your review to test\n",
    "review = \"good\" \n",
    "prediction_transformed = vectorizer.transform([review])\n",
    "\n",
    "print(clf.predict(prediction_transformed), clf.predict_proba(prediction_transformed))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMorHjucWymJaxpGK0Bk0Vn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
